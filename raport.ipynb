{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YouTube trending videos\n",
    "\n",
    "## Projekt Eksploracji Danych\n",
    "\n",
    "### Autorzy:\n",
    "- Adrian Kotarski 127346\n",
    "- Patryk Szczuczko 127215"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wstępne przetwarzanie danych i atrybuty tekstowe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Importy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcja mapująca thumbnail_link na video_id\n",
    "def map_video_id_from_thumbnail_link(thumbnail_link):\n",
    "    return thumbnail_link.split(sep='/')[-2]\n",
    "\n",
    "\n",
    "# Funkcja parsująca atrybut trending_date do struktury Timestamp\n",
    "def trending_date_to_timestamp(trending_date):\n",
    "    date_parts = list(map(int, str(trending_date).split(sep='.')))\n",
    "    return pd.Timestamp(2000 + date_parts[0], date_parts[2], date_parts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie i wstępne przetworzenie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Załadowanie danych z pliku\n",
    "data_GB = pd.read_csv(\"GB_videos_5p.csv\", delimiter=';', encoding='latin1')\n",
    "data_US = pd.read_csv(\"US_videos_5p.csv\", delimiter=';')\n",
    "\n",
    "# Dodanie atrybutu country, który rozróżnia dane pochodzące z US i GB\n",
    "data_GB['country'] = \"GB\"\n",
    "data_US['country'] = \"US\"\n",
    "\n",
    "# Złączenie danych w jeden zbiór\n",
    "data = pd.concat([data_GB, data_US])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Przypisanie nowych video_id dla wpisów z 'video_id' == #NAZWA? na podstawie thumbnail_link\n",
    "data.loc[data['video_id'] == \"#NAZWA?\", \"video_id\"] = \\\n",
    "    data['thumbnail_link'].map(lambda thumbnail_link: map_video_id_from_thumbnail_link(thumbnail_link))\n",
    "\n",
    "# Zmiana nazwy atrybuty na poprawną (bez spacji na końcu)\n",
    "data = data.rename(columns={\"description \": \"description\"})\n",
    "\n",
    "# Zmiana struktury danych atrybutu trending_date\n",
    "data['trending_date'] = data['trending_date'].map(lambda trending_date: trending_date_to_timestamp(trending_date))\n",
    "\n",
    "# Utworzenie mappingów na potrzeby kolejnych atrybutów\n",
    "video_id_to_trending_count_mapping = data['video_id'].value_counts().to_dict()\n",
    "video_id_to_last_trending_date_mapping = data.sort_values('trending_date', ascending=False).drop_duplicates(\"video_id\") \\\n",
    "    .set_index('video_id').to_dict()['trending_date']\n",
    "\n",
    "# Usunięcie duplikatów filmów po video_id\n",
    "data = data.sort_values('views').drop_duplicates(\"video_id\").sort_index().reset_index(drop=True)\n",
    "\n",
    "# Utworzenie atrybutów: liczba wystąpień w zakładce Trending oraz data ostatniego pojawienia się filmu w zakładce Trending\n",
    "data['trending_count'] = data['video_id'].map(lambda video_id: video_id_to_trending_count_mapping[video_id])\n",
    "data['last_trending_date'] = data['video_id'].map(lambda video_id: video_id_to_last_trending_date_mapping[video_id])\n",
    "\n",
    "# Zmiana nazwy atrybutu, który tak naprawdę jest teraz pierwszą datą wystąpienia filmiku w zakładce Trending\n",
    "data = data.rename(columns={\"trending_date\": \"first_trending_date\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcja obliczająca liczbę tagów z atrybutu tags\n",
    "def tags_to_number_of_tags(tags):\n",
    "    return 0 if tags == \"[none]\" else len(str(tags).split(sep='|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Utworzenie nowych atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utworzenie nowych atrybutów na podstawie już obecnych\n",
    "data['likes_views_ratio'] = data['likes'] / data['views']\n",
    "data['dislikes_views_ratio'] = data['dislikes'] / data['views']\n",
    "data['comment_count_views_ratio'] = data['comment_count'] / data['views']\n",
    "\n",
    "# Dodanie atrybutów: długości tytułu oraz długości opisu\n",
    "data['title_length'] = data.apply(lambda row: len(row['title']), axis=1)\n",
    "data['description_length'] = data.apply(lambda row: len(str(row['description'])), axis=1)\n",
    "\n",
    "# Uproszczenie danych atrybutu publish_time - usunięcie czasu, zostawienie tylko daty\n",
    "data['publish_time'] = data['publish_time'].map(lambda publish_time: pd.Timestamp(pd.Timestamp(publish_time).date()))\n",
    "\n",
    "# Utworzenie dwóch nowych atrybutów: rok oraz miesiąc publikacji\n",
    "data['publish_time_year'] = data['publish_time'].map(lambda publish_time: publish_time.year)\n",
    "data['publish_time_month'] = data['publish_time'].map(lambda publish_time: publish_time.month)\n",
    "\n",
    "# Utworzenie atrybutu, który opisuje ile czasu (w dniach) video potrzebowało aby pojawić się w proponowanych\n",
    "data['days_from_publish_time_to trending_date'] = data['first_trending_date'] - data['publish_time']\n",
    "data['days_from_publish_time_to trending_date'] = data['days_from_publish_time_to trending_date'].map(\n",
    "    lambda timedelta: timedelta.days)\n",
    "\n",
    "# Dodanie atrybutów: liczby tagów w atrybucie tags oraz liczba linków w opisie\n",
    "data['number_of_tags'] = data['tags'].map(lambda tags: tags_to_number_of_tags(tags))\n",
    "data['number_of_links'] = data['description'].map(lambda description: str(description).count(\"http\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykresy i charakterystyka nowych atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for column in ['number_of_tags', 'number_of_links', 'title_length', 'description_length']:\n",
    "    # Rysowanie wykresów pudełkowych interesujących atrybutów liczbowych (pierwszy wykres - całość danych, drugi wykres -\n",
    "    # dane w podziale na kraj US lub GB)\n",
    "    data.boxplot(column=[column])\n",
    "    data.boxplot(by='country', column=[column])\n",
    "    plt.suptitle('')\n",
    "    plt.show()\n",
    "\n",
    "    # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach pudełkowych\n",
    "    print(data[column].describe())\n",
    "    print(data.groupby('country')[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcja wydobywająca nazwę kategorii video wraz z ID\n",
    "def extract_category_with_id_from_json_items(items):\n",
    "    items_str = str(items)\n",
    "    category_id = items_str[items_str.index(\"id\\': \\'\") + 6:items_str.index(\"\\', \\'snippet\")]\n",
    "    category = items_str[items_str.index(\"title\\': \\'\") + 9:items_str.index(\"\\', \\'assignable\")]\n",
    "    return int(category_id), category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Przemapowanie kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Załadowanie pliku z opisem kategorii (zawartość pliku GB zawiera się w zawartości pliku US jeśli chodzi o przypisanie nazwy kategorii do ID)\n",
    "category_names = pd.read_json('US_category_id.json')\n",
    "\n",
    "# Przemapowanie ID kategorii na jej nazwę\n",
    "category_mapping = dict(\n",
    "    category_names['items'].map(lambda items: extract_category_with_id_from_json_items(items)).tolist())\n",
    "data['category_id'].replace(category_mapping, inplace=True)\n",
    "\n",
    "# W związku z zastąpieniem ID kategorii przez jej nazwę to zmiana nazwy atrybutu\n",
    "data = data.rename(columns={\"category_id\": \"category\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def assign_category_from_youtube_api(video_id, category):\n",
    "    if str(category) == \"nan\":\n",
    "        values = trending_with_category.loc[trending_with_category[\"video_id\"] == video_id][\"category\"].values\n",
    "        if values.size != 0:\n",
    "            return values[0]\n",
    "    return category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przypisanie kategorii z Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Przypisanie kategorii z Youtube API dla tych filmów, które miały pustą kategorię\n",
    "trending_with_category = pd.read_csv(\"trending_with_category.csv\", sep=\";\")\n",
    "data[\"category\"] = data\\\n",
    "    .apply(lambda row: assign_category_from_youtube_api(row[\"video_id\"], row[\"category\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcja pomocnicza do wykresu liczba video z przypisaną kategorią vs liczba video bez przypisanej kategorii\n",
    "def value_vs_non_value_in_category_id(category_id):\n",
    "    return \"No\" if str(category_id) == \"nan\" else \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wykresy odnośnie kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rysowanie wykresu obrazującego rozkład kategorii wśród video z przypisanymi kategoriami\n",
    "category_count_plot = sns.countplot(x='category', data=data)\n",
    "category_count_plot.set_xticklabels(category_count_plot.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()\n",
    "\n",
    "# Rysowanie wykresu obrazującego porównanie liczby video z przypisaną kategorią do liczby video bez przypisanej kategorii\n",
    "value_count = data['category'].map(lambda category_id: value_vs_non_value_in_category_id(category_id)).value_counts()\n",
    "sns.barplot(value_count.index, value_count.values).set_title(\"Video has category\")\n",
    "plt.show()\n",
    "\n",
    "# Wypisanie statystyk odnośnie liczby video z daną kategorią (lub bez)\n",
    "print(data['category'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejne wykresy i charakterystyki nowych atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wykres liczby video w zależności od miesiąca w którym zostały opublikowane\n",
    "sns.countplot(x='publish_time_month', data=data)\n",
    "plt.show()\n",
    "\n",
    "for group in ['publish_time_month', 'category']:\n",
    "    for column in ['views', 'likes', 'comment_count']:\n",
    "        # Rysowanie wykresów pudełkowych dla wybranych atrybutów\n",
    "        # bez obserwacji odstających - aby wykres był czytelniejszy\n",
    "        data.boxplot(by=group, column=[column], showfliers=False)\n",
    "        if group == 'category':\n",
    "            plt.xticks(rotation='vertical')\n",
    "        plt.suptitle('')\n",
    "        plt.show()\n",
    "\n",
    "        # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach\n",
    "        print(data.groupby(group)[column].describe())\n",
    "\n",
    "# Wykres video z włączonymi komentarzami vs video z wyłączonymi komentarzami\n",
    "sns.countplot(x='comments_disabled', data=data)\n",
    "plt.show()\n",
    "\n",
    "for column in ['views', 'likes']:\n",
    "    # Rysowanie wykresów pudełkowych dla wybranych atrybutów\n",
    "    # bez obserwacji odstających - aby wykres był czytelniejszy\n",
    "    data.boxplot(by='comments_disabled', column=[column], showfliers=False)\n",
    "    plt.suptitle('')\n",
    "    plt.show()\n",
    "    # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach\n",
    "    print(data.groupby('comments_disabled')[column].describe())\n",
    "\n",
    "# Wykres video z włączonymi ocenami vs video z wyłączonymi ocenami\n",
    "sns.countplot(x='ratings_disabled', data=data)\n",
    "plt.show()\n",
    "\n",
    "for column in ['views', 'comment_count']:\n",
    "    # Rysowanie wykresów pudełkowych dla wybranych atrybutów\n",
    "    # bez obserwacji odstających - aby wykres był czytelniejszy\n",
    "    data.boxplot(by='ratings_disabled', column=[column], showfliers=False)\n",
    "    plt.suptitle('')\n",
    "    plt.show()\n",
    "    # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach\n",
    "    print(data.groupby('ratings_disabled')[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Atrybuty wizualne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje pobierające miniaturki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcja pobierająca miniaturke w rozdzielczości 120x90 z podanego linku\n",
    "def download_thumbnail(thumbnail_link, video_id):\n",
    "    if not os.path.exists(\"thumbnails\\\\\" + video_id + \".png\"):\n",
    "        try:\n",
    "            resp = urllib.request.urlopen(thumbnail_link)\n",
    "            image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            cv2.imwrite(\"thumbnails\\\\\" + video_id + \".png\", image)\n",
    "        except urllib.error.HTTPError:\n",
    "            pass\n",
    "\n",
    "\n",
    "# Funkcja pobierająca miniaturke w rozdzielczości 480x360 z podanego linku\n",
    "def download_hq_thumbnail(thumbnail_link, video_id):\n",
    "    if not os.path.exists(\"thumbnails_hq\\\\\" + video_id + \".png\"):\n",
    "        try:\n",
    "            index = thumbnail_link.find(\"default.jpg\")\n",
    "            resp = urllib.request.urlopen(thumbnail_link[:index] + \"hq\" + thumbnail_link[index:])\n",
    "            image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            cv2.imwrite(\"thumbnails_hq\\\\\" + video_id + \".png\", image)\n",
    "        except urllib.error.HTTPError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobranie miniaturek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Część kodu odpowiedzialna za pobranie miniaturek\n",
    "for _, row in data.iterrows():\n",
    "    download_thumbnail(row['thumbnail_link'], row['video_id'])\n",
    "    download_hq_thumbnail(row['thumbnail_link'], row['video_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcja wczytująca i przetwarzająca miniaturkę (obicięcie 10 górnych i dolnych pikseli w celi wyeliminowania czarnych pasków)\n",
    "def load_and_process_rgb_thumbnail(video_id):\n",
    "    try:\n",
    "        image = cv2.imread(\"thumbnails\\\\\" + video_id + \".png\")[10:-10]\n",
    "        image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return np.concatenate((extract_average(image), extract_mode(image),\n",
    "                               extract_average(image_hsv), extract_mode(image_hsv),\n",
    "                               extract_count_pixels_by_hue(image_hsv), extract_rms_contrast(image_gray)), axis=None)\n",
    "    except:\n",
    "        return 19 * ([float(\"NaN\")])\n",
    "\n",
    "\n",
    "# Funkcja wyliczająca średnie dla miniaturki filmu\n",
    "def extract_average(image):\n",
    "    return image.mean(axis=0).mean(axis=0)\n",
    "\n",
    "\n",
    "# Funkcja wyliczająca dominantę dla miniaturki filmu\n",
    "def extract_mode(image):\n",
    "    colors, count = np.unique(image.reshape(-1, image.shape[-1]), axis=0, return_counts=True)\n",
    "    return colors[count.argmax()]\n",
    "\n",
    "\n",
    "# Funkcja zliczająca pixele w ramach poszczególnych przedziałów wartości hue\n",
    "def extract_count_pixels_by_hue(image_hsv):\n",
    "    hue = image_hsv[:, :, 0]\n",
    "    red = np.size(hue[(hue < 15) | (hue >= 165)])\n",
    "    yellow = np.size(hue[(hue >= 15) & (hue < 45)])\n",
    "    green = np.size(hue[(hue >= 45) & (hue < 75)])\n",
    "    cyan = np.size(hue[(hue >= 75) & (hue < 105)])\n",
    "    blue = np.size(hue[(hue >= 105) & (hue < 135)])\n",
    "    magenta = np.size(hue[(hue >= 135) & (hue < 165)])\n",
    "    return red, yellow, green, cyan, blue, magenta\n",
    "\n",
    "\n",
    "# Funckja wyliczająca kontrast RMS (root mean square)\n",
    "def extract_rms_contrast(image_gray):\n",
    "    return image_gray.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Utworzenie atrubytów wizualnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utworzenie atrvbutów wizualnych\n",
    "data['average_red'], data['average_green'], data['average_blue'], \\\n",
    "data['mode_red]'], data['mode_green'], data['mode_blue'], \\\n",
    "data['average_hue'], data['average_saturation'], data['average_value'], \\\n",
    "data['mode_hue'], data['mode_saturation'], data['mode_value'], \\\n",
    "data['hue_red'], data['hue_yellow'], data['hue_green'], data['hue_cyan'], data['hue_blue'], data['hue_magenta'], \\\n",
    "data['rms_contrast'] = zip(*data['video_id'].map(lambda video_id: load_and_process_rgb_thumbnail(video_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wykres oraz charakterystyki tych atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wykres pudełkowy liczby pikseli obrazka dla każdego z odcieni hue\n",
    "hue_colors = ['hue_red', 'hue_yellow', 'hue_green', 'hue_cyan', 'hue_blue', 'hue_magenta']\n",
    "data.boxplot(column=hue_colors)\n",
    "plt.title(\"Liczba pikseli w danym odcieniu Hue\")\n",
    "plt.show()\n",
    "\n",
    "# Wypisanie statystyk\n",
    "for column in hue_colors:\n",
    "    print(data[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie atrybutów wizualnych wyrażających emocje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dodanie atrybutów wyrażających emocję na miniaturce ('angry','disgust','fear','happy','sad','surprise','neutral')\n",
    "emotion_vectors = pd.read_csv(\"emotions_hq.csv\", delimiter=',')\n",
    "data = pd.merge(data, emotion_vectors, how='left', on='video_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykres oraz statystyki tych atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wypisanie statystyk liczby emocji dla wszystkich obrazków w podziale na typ\n",
    "emotion_count = {}\n",
    "for emotion in ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']:\n",
    "    count = np.count_nonzero(data[emotion] > 0)\n",
    "    emotion_count[emotion] = count\n",
    "    print(emotion + \": \" + str(count))\n",
    "\n",
    "# Rysowanie wykresu liczby emocji dla wszystkich obrazków w podziale na typ\n",
    "plt.bar(emotion_count.keys(), emotion_count.values())\n",
    "plt.title(\"Emotion counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korelacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rysowanie wykresu korelacji atrybutów\n",
    "f = plt.figure(figsize=(30, 30))\n",
    "plt.matshow(data.corr(), fignum=f.number, cmap=plt.cm.get_cmap(\"coolwarm\"))\n",
    "plt.xticks(range(data.corr().shape[1]), data.corr().columns, fontsize=20, rotation=90)\n",
    "plt.yticks(range(data.corr().shape[1]), data.corr().columns, fontsize=20)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=15)\n",
    "plt.suptitle(\"Correlation\", fontsize=64)\n",
    "plt.show()\n",
    "\n",
    "# Wypisanie macierzy korelacji\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ocena atrybutów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Uczenie pół-nadzorowane"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wczytanie i przetworzenie danych do uczenia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Załadowanie danych\n",
    "data = pd.read_csv(\"trending.csv\", sep=\";\")\n",
    "\n",
    "# Z całego zbioru danych wybieramy te filmy, które mają opisaną kategorią i mają miniaturkę\n",
    "data_with_category = data.loc[data[\"category\"].notnull() & data[\"average_red\"].notna()]\n",
    "\n",
    "# Wyznaczony zbiór dzielimy na zbiór atrybutów i klas\n",
    "features = data_with_category[data_with_category.columns.difference(\n",
    "    [\"category\", \"video_id\", \"first_trending_date\", \"title\", \"channel_title\", \"publish_time\", \"tags\", \"thumbnail_link\",\n",
    "     \"description\", \"country\", \"last_trending_date\"], sort=False)].copy()\n",
    "target = data_with_category[\"category\"].copy()\n",
    "\n",
    "# Wyznaczamy wagi klas dla random forest\n",
    "category_dict = data_with_category['category'].value_counts(dropna=True).to_dict()\n",
    "max_category_count = max(category_dict.values())\n",
    "category_weight = {k: max_category_count / v for k, v in category_dict.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Klasyfikator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tworzymy i trenujemy klasyfikator\n",
    "random_forest = RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300,\n",
    "                                       max_features='auto', class_weight=category_weight, random_state=12)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.1, random_state=12)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przedstawienie wyników"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statystyki klasyfikatora\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ground truth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wczytanie danych i weryfikacja klasyfikatora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "ground_truth = pd.read_csv(\"trending_with_category.csv\", sep=\";\")\n",
    "ground_truth = ground_truth.loc[ground_truth[\"category\"].notnull() & ground_truth[\"average_red\"].notna()]\n",
    "\n",
    "features_ground_truth = ground_truth[ground_truth.columns.difference(\n",
    "    [\"category\", \"video_id\", \"first_trending_date\", \"title\", \"channel_title\", \"publish_time\", \"tags\", \"thumbnail_link\",\n",
    "     \"description\", \"country\", \"last_trending_date\"], sort=False)].copy()\n",
    "target_ground_truth = ground_truth[\"category\"].copy()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(features_ground_truth, target_ground_truth, test_size=0.000000001, random_state=12)\n",
    "\n",
    "pred_ground_truth = random_forest.predict(train_x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wypisanie statystyk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statystyki klasyfikatora\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(train_y, pred_ground_truth))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(train_y, pred_ground_truth))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Przygotowanie danych non-trending"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcje"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Funkcja pobierająca miniaturke w rozdzielczości 120x90 z podanego linku\n",
    "def download_non_trending_thumbnail(thumbnail_link, video_id):\n",
    "    if not os.path.exists(\"non_trending_thumbnails\\\\\" + video_id + \".png\"):\n",
    "        try:\n",
    "            resp = urllib.request.urlopen(thumbnail_link)\n",
    "            image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            cv2.imwrite(\"non_trending_thumbnails\\\\\" + video_id + \".png\", image)\n",
    "        except urllib.error.HTTPError:\n",
    "            pass\n",
    "\n",
    "\n",
    "# Funkcja pobierająca miniaturke w rozdzielczości 480x360 z podanego linku\n",
    "def download_non_trending_hq_thumbnail(thumbnail_link, video_id):\n",
    "    if not os.path.exists(\"non_trending_thumbnails_hq\\\\\" + video_id + \".png\"):\n",
    "        try:\n",
    "            index = thumbnail_link.find(\"default.jpg\")\n",
    "            resp = urllib.request.urlopen(thumbnail_link[:index] + \"hq\" + thumbnail_link[index:])\n",
    "            image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            cv2.imwrite(\"non_trending_thumbnails_hq\\\\\" + video_id + \".png\", image)\n",
    "        except urllib.error.HTTPError:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wczytanie danhych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Załadowanie danych z pliku\n",
    "data = pd.read_csv(\"video_from_youtube_data_api.csv\", delimiter=';')\n",
    "data = data.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pobranie miniaturek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Część kodu odpowiedzialna za pobranie miniaturek\n",
    "for _, row in data.iterrows():\n",
    "    download_non_trending_thumbnail(row['thumbnail_link'], row['video_id'])\n",
    "    download_non_trending_hq_thumbnail(row['thumbnail_link'], row['video_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utworzenie nowych atrybutów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Utworzenie nowych atrybutów na podstawie już obecnych\n",
    "data['likes_views_ratio'] = data['likes'] / data['views']\n",
    "data['dislikes_views_ratio'] = data['dislikes'] / data['views']\n",
    "data['comment_count_views_ratio'] = data['comment_count'] / data['views']\n",
    "\n",
    "# Dodanie atrybutów: długości tytułu oraz długości opisu\n",
    "data['title_length'] = data.apply(lambda row: len(row['title']), axis=1)\n",
    "data['description_length'] = data.apply(lambda row: len(str(row['description'])), axis=1)\n",
    "\n",
    "data[\"publish_time\"] = data[\"publish_time\"].map(\n",
    "    lambda publish_time: pd.Timestamp(pd.Timestamp(publish_time).date()))\n",
    "\n",
    "# Utworzenie dwóch nowych atrybutów: rok oraz miesiąc publikacji\n",
    "data['publish_time_year'] = data['publish_time'].map(lambda publish_time: publish_time.year)\n",
    "data['publish_time_month'] = data['publish_time'].map(lambda publish_time: publish_time.month)\n",
    "\n",
    "# Dodanie atrybutów: liczby tagów w atrybucie tags oraz liczba linków w opisie\n",
    "data['number_of_tags'] = data['tags'].map(lambda tags: tags_to_number_of_tags(tags))\n",
    "data['number_of_links'] = data['description'].map(lambda description: str(description).count(\"http\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rysowanie wykresów i wypisanie statystyk tych powstałych atrybutów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in ['number_of_tags', 'number_of_links', 'title_length', 'description_length']:\n",
    "    # Rysowanie wykresów pudełkowych interesujących atrybutów liczbowych (pierwszy wykres - całość danych)\n",
    "    data.boxplot(column=[column])\n",
    "    plt.suptitle('')\n",
    "    plt.show()\n",
    "\n",
    "    # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach pudełkowych\n",
    "    print(data[column].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przemapowanie ID kategorii na nazwę"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Załadowanie pliku z opisem kategorii (zawartość pliku GB zawiera się w zawartości pliku US jeśli chodzi o przypisanie nazwy kategorii do ID)\n",
    "category_names = pd.read_json('US_category_id.json')\n",
    "\n",
    "# Przemapowanie ID kategorii na jej nazwę\n",
    "category_mapping = dict(\n",
    "    category_names['items'].map(lambda items: extract_category_with_id_from_json_items(items)).tolist())\n",
    "data['category_id'].replace(category_mapping, inplace=True)\n",
    "\n",
    "# W związku z zastąpieniem ID kategorii przez jej nazwę to zmiana nazwy atrybutu\n",
    "data = data.rename(columns={\"category_id\": \"category\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rysowanie wykresów i wypisanie statystyk odnośnie kategorii"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rysowanie wykresu obrazującego rozkład kategorii wśród video z przypisanymi kategoriami\n",
    "category_count_plot = sns.countplot(x='category', data=data)\n",
    "category_count_plot.set_xticklabels(category_count_plot.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()\n",
    "\n",
    "# Rysowanie wykresu obrazującego porównanie liczby video z przypisaną kategorią do liczby video bez przypisanej kategorii\n",
    "value_count = data['category'].map(lambda category_id: value_vs_non_value_in_category_id(category_id)).value_counts()\n",
    "sns.barplot(value_count.index, value_count.values).set_title(\"Video has category\")\n",
    "plt.show()\n",
    "\n",
    "# Wypisanie statystyk odnośnie liczby video z daną kategorią (lub bez)\n",
    "print(data['category'].value_counts(dropna=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rysowanie wykresów i wypisanie statystyk dla pozostałych atrybutów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wykres liczby video w zależności od miesiąca w którym zostały opublikowane\n",
    "sns.countplot(x='publish_time_month', data=data)\n",
    "plt.show()\n",
    "\n",
    "for group in ['publish_time_month', 'category']:\n",
    "    for column in ['views', 'likes', 'comment_count']:\n",
    "        # Rysowanie wykresów pudełkowych dla wybranych atrybutów\n",
    "        # bez obserwacji odstających - aby wykres był czytelniejszy\n",
    "        data.boxplot(by=group, column=[column], showfliers=False)\n",
    "        if group == 'category':\n",
    "            plt.xticks(rotation='vertical')\n",
    "        plt.suptitle('')\n",
    "        plt.show()\n",
    "\n",
    "        # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach\n",
    "        print(data.groupby(group)[column].describe())\n",
    "\n",
    "# Wykres video z włączonymi komentarzami vs video z wyłączonymi komentarzami\n",
    "sns.countplot(x='comments_disabled', data=data)\n",
    "plt.show()\n",
    "\n",
    "for column in ['views', 'likes']:\n",
    "    # Rysowanie wykresów pudełkowych dla wybranych atrybutów\n",
    "    # bez obserwacji odstających - aby wykres był czytelniejszy\n",
    "    data.boxplot(by='comments_disabled', column=[column], showfliers=False)\n",
    "    plt.suptitle('')\n",
    "    plt.show()\n",
    "    # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach\n",
    "    print(data.groupby('comments_disabled')[column].describe())\n",
    "\n",
    "# Wykres video z włączonymi ocenami vs video z wyłączonymi ocenami\n",
    "sns.countplot(x='ratings_disabled', data=data)\n",
    "plt.show()\n",
    "\n",
    "for column in ['views', 'comment_count']:\n",
    "    # Rysowanie wykresów pudełkowych dla wybranych atrybutów\n",
    "    # bez obserwacji odstających - aby wykres był czytelniejszy\n",
    "    data.boxplot(by='ratings_disabled', column=[column], showfliers=False)\n",
    "    plt.suptitle('')\n",
    "    plt.show()\n",
    "    # Wypisanie statystyk zwizualizowanych na wcześniejszych wykresach\n",
    "    print(data.groupby('ratings_disabled')[column].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utworzenie atrybutów wizualnych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Utworzenie atrvbutów wizualnych\n",
    "data['average_red'], data['average_green'], data['average_blue'], \\\n",
    "data['mode_red]'], data['mode_green'], data['mode_blue'], \\\n",
    "data['average_hue'], data['average_saturation'], data['average_value'], \\\n",
    "data['mode_hue'], data['mode_saturation'], data['mode_value'], \\\n",
    "data['hue_red'], data['hue_yellow'], data['hue_green'], data['hue_cyan'], data['hue_blue'], data['hue_magenta'], \\\n",
    "data['rms_contrast'] = zip(*data['video_id'].map(lambda video_id: load_and_process_rgb_thumbnail(video_id)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rysowanie wykresów i wypisanie statystyk dla tych atrybutów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wykres pudełkowy liczby pikseli obrazka dla każdego z odcieni hue\n",
    "hue_colors = ['hue_red', 'hue_yellow', 'hue_green', 'hue_cyan', 'hue_blue', 'hue_magenta']\n",
    "data.boxplot(column=hue_colors)\n",
    "plt.title(\"Liczba pikseli w danym odcieniu Hue\")\n",
    "plt.show()\n",
    "\n",
    "# Wypisanie statystyk\n",
    "for column in hue_colors:\n",
    "    print(data[column].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utworzenie atrybutów wyrażających emocje"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dodanie atrybutów wyrażających emocję na miniaturce ('angry','disgust','fear','happy','sad','surprise','neutral')\n",
    "emotion_vectors = pd.read_csv(\"non_trending_emotions_hq.csv\", delimiter=',')\n",
    "data = pd.merge(data, emotion_vectors, how='left', on='video_id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rysowanie wykresów i wypisanie statystyk dla atrybutów związanych z wyrażaniem emocji"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wypisanie statystyk liczby emocji dla wszystkich obrazków w podziale na typ\n",
    "emotion_count = {}\n",
    "for emotion in ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']:\n",
    "    count = np.count_nonzero(data[emotion] > 0)\n",
    "    emotion_count[emotion] = count\n",
    "    print(emotion + \": \" + str(count))\n",
    "\n",
    "# Rysowanie wykresu liczby emocji dla wszystkich obrazków w podziale na typ\n",
    "plt.bar(emotion_count.keys(), emotion_count.values())\n",
    "plt.title(\"Emotion counts\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Korelacja"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rysowanie wykresu korelacji atrybutów\n",
    "f = plt.figure(figsize=(30, 30))\n",
    "plt.matshow(data.corr(), fignum=f.number, cmap=plt.cm.get_cmap(\"coolwarm\"))\n",
    "plt.xticks(range(data.corr().shape[1]), data.corr().columns, fontsize=20, rotation=90)\n",
    "plt.yticks(range(data.corr().shape[1]), data.corr().columns, fontsize=20)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=15)\n",
    "plt.suptitle(\"Correlation\", fontsize=64)\n",
    "plt.show()\n",
    "\n",
    "# Wypisanie macierzy korelacji\n",
    "print(data.corr())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Klasyfikator trending vs non-trending"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Załadowanie i przygotowanie danych do uczenia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Załadowanie danych\n",
    "trending = pd.read_csv(\"trending.csv\", sep=\";\")\n",
    "non_trending = pd.read_csv(\"non_trending.csv\", sep=\";\")\n",
    "\n",
    "# Dodanie klasy do danych\n",
    "trending[\"is_trending\"] = True\n",
    "non_trending[\"is_trending\"] = False\n",
    "\n",
    "# Połączenie zbioru danych w jeden\n",
    "data = pd.concat([trending, non_trending], sort=False)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Z całego zbioru danych wybieramy te filmy, które mają miniaturkę\n",
    "data = data.loc[data[\"average_red\"].notna()]\n",
    "data = data.loc[data[\"likes_views_ratio\"].notna()]\n",
    "\n",
    "# Wyznaczony zbiór dzielimy na zbiór atrybutów i klas\n",
    "features = data[data.columns.difference(\n",
    "    [\"category\", \"video_id\", \"first_trending_date\", \"title\", \"channel_title\", \"publish_time\", \"tags\", \"thumbnail_link\",\n",
    "     \"description\", \"country\", \"last_trending_date\", \"is_trending\", \"video_error_or_removed\", \"trending_count\",\n",
    "     \"days_from_publish_time_to trending_date\"], sort=False)].copy()\n",
    "target = data[\"is_trending\"].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utworzenie i trenowanie pierwszego klasyfikatora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tworzymy i trenujemy klasyfikator\n",
    "random_forest = RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100,\n",
    "                                       max_features='auto', random_state=12)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=12)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wypisanie wyników dla pierwszego klasyfikatora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statystyki klasyfikatora\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utworzenie i trenowanie drugiego klasyfikatora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(alpha=1, max_iter=1000, random_state=12)\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wypisanie wyników dla drugiego klasyfikatora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statystyki klasyfikatora\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}